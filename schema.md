# Database Schemas & Data Structures

This document serves as a reference for the database models and data structures used in the Personalised AI Tutor project.

---

## 1. MongoDB (Application Data - Node.js Backend)

The backend uses **Mongoose** to manage structured application data in MongoDB.

### **User Model (`User.model.js`)**
Stores student profile and academic context.
- `username` (String, Required): Display name.
- `email` (String, Unique, Required): Login credential.
- `password` (String, Required): Hashed password.
- `batch` (String, Required): Graduation year or cohort.
- `regulation` (Number, Required): Academic regulation year.
- `university` (String, Required): Institution name.

### **Subject Model (`Subject.model.js`)**
Stores metadata for educational materials.
- `title` (String, Required): Subject name.
- `description` (String, Required): Brief overview.
- `subject_code` (String, Unique, Required): Identifier (e.g., "CS3491").
- `createdBy` (ObjectId, Ref: 'User'): Reference to the user who added it.
- **Files Metadata (`fileMetadataSchema`):**
    - `filename` (String): Stored filename in `uploads/`.
    - `originalName` (String): Original user filename.
    - `size` (Number): File size in bytes.
    - `contentType` (String): MIME type (e.g., `application/pdf`).
- **Required Files:** `syllabus`, `notes`.
- **Optional Files:** `pastpaper`.
- **Structured Syllabus (`units` array):**
    - `unitName` (String): Title of the unit (e.g., "Unit I: Basics").
    - `topics` (Array):
        - `topicName` (String): Title of the topic.
        - `subtopics` (Array of Strings): Optional detailed sub-items.

### **Quiz Model (`Quiz.model.js`)**
Stores generated or manual assessment questions.
- `subject_code` (String, Ref: 'Subject'): Links to a subject.
- `topic` (String, Required): Specific unit or topic.
- `createdBy` (ObjectId, Ref: 'User'): Owner of the quiz.
- `difficulty` (Enum): `easy`, `medium`, `hard` (Default: `medium`).
- `isAIGenerated` (Boolean): Whether generated by the RAG system.
- **Questions Array (`questionSchema`):**
    - `question` (String, Required): Question text.
    - `type` (Enum): `radio`, `checkbox`, `paragraph`.
    - `options` (Array of Strings): Choices for MCQ.
    - `correctAnswer` (Mixed): String or Array of indices (Optional for 'paragraph').

### **QuizAttempt Model (`QuizAttempt.model.js`)**
Tracks student performance history.
- `quiz` (ObjectId, Ref: 'Quiz'): Relationship.
- `user` (ObjectId, Ref: 'User'): Participant.
- `score` (Number): Points achieved.
- `maxScore` (Number): Total possible points.
- `percentageScore` (Number): Calculated percentage.
- `timeSpent` (Number): Duration in seconds.
- `completed` (Boolean): Completion status.
- **Answers Array:** Tracks `questionId`, `userAnswer`, and `isCorrect`.

### **TopicProgress Model (`TopicProgress.model.js`)**
Tracks topic-level mastery for adaptive learning.
- `user` (ObjectId, Ref: 'User'): Relationship.
- `subject_code` (String, Required): Course identifier.
- `topic` (String, Required): Matches the syllabus topic exactly.
- `totalQuestions` (Number): Lifetime questions attempted.
- `correctQuestions` (Number): Lifetime correct answers.
- `recentAccuracy` (Number): Rolling average or last N accuracy.
- `masteryScore` (Number): Progress from 0 to 1.
- `currentDifficulty` (Enum): `easy`, `medium`, `hard`.
- `lastPracticed` (Date): Most recent session.

---

## 2. ChromaDB (Vector Search - Python RAG Engine)

The AI engine uses **ChromaDB** for local vector storage, isolated by subject.

- **Storage Location:** `RAG-backend/chroma_db/{subject_code}/`
- **Embedding Model:** `sentence-transformers/all-MiniLM-L6-v2`
- **Chunk Config:** `CHUNK_SIZE = 1000`, `CHUNK_OVERLAP = 200`
- **Data Metadata:**
    - `subject_code`: The unique identifier for the course.
    - `source`: The original filename of the document.
    - `source_type`: Category of the source (`syllabus`, `notes`, or `past_papers`).
- **Content:** Processed and OCR-cleaned text chunks from course PDFs.

---

## 3. Local LLM Configuration

The system performs inference locally using **Ollama**.
- **Default Model:** `llama3.1:8b`
- **Primary Tasks:** MCQ generation, Flashcard extraction, and query-based retrieval augmentation.
